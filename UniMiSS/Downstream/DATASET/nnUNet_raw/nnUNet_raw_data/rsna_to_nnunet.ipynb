{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, subfiles\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    " \n",
    "def get_identifiers_from_splitted_files(folder: str):\n",
    "    \n",
    "    uniques = np.unique([i[:-7] for i in subfiles(folder, suffix='.nii.gz', join=False)])\n",
    "    return uniques\n",
    " \n",
    "def generate_dataset_json(output_file: str, imagesTr_dir: str, imagesTs_dir: str, modalities: Tuple,\n",
    "                          labels: dict, dataset_name: str, license: str = \"AIML\", dataset_description: str = \"\",\n",
    "                          dataset_reference=\"oai-zib\", dataset_release='11/2021'):\n",
    "    \"\"\"\n",
    "    :param output_file: This needs to be the full path to the dataset.json you intend to write, so\n",
    "    output_file='DATASET_PATH/dataset.json' where the folder DATASET_PATH points to is the one with the\n",
    "    imagesTr and labelsTr subfolders\n",
    "    :param imagesTr_dir: path to the imagesTr folder of that dataset\n",
    "    :param imagesTs_dir: path to the imagesTs folder of that dataset. Can be None\n",
    "    :param modalities: tuple of strings with modality names. must be in the same order as the images (first entry\n",
    "    corresponds to _0000.nii.gz, etc). Example: ('T1', 'T2', 'FLAIR').\n",
    "    :param labels: dict with int->str (key->value) mapping the label IDs to label names. Note that 0 is always\n",
    "    supposed to be background! Example: {0: 'background', 1: 'edema', 2: 'enhancing tumor'}\n",
    "    :param dataset_name: The name of the dataset. Can be anything you want\n",
    "    :param license:\n",
    "    :param dataset_description:\n",
    "    :param dataset_reference: website of the dataset, if available\n",
    "    :param dataset_release:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_identifiers = get_identifiers_from_splitted_files(imagesTr_dir)\n",
    " \n",
    "    if imagesTs_dir is not None:\n",
    "        test_identifiers = get_identifiers_from_splitted_files(imagesTs_dir)\n",
    "    else:\n",
    "        test_identifiers = []\n",
    " \n",
    "    json_dict = {}\n",
    "    json_dict['name'] = \"bleedbrain\"\n",
    "    json_dict['description'] = \"bleedbrain\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = dataset_reference\n",
    "    json_dict['licence'] = license\n",
    "    json_dict['release'] = dataset_release\n",
    "    json_dict['modality'] = {\"0\": \"CT\"}\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"foreground\",\n",
    "    }\n",
    " \n",
    "    json_dict['numTraining'] = len(train_identifiers)\n",
    "    json_dict['numTest'] = len(test_identifiers)\n",
    "    json_dict['training'] = [\n",
    "        {'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i\n",
    "        in\n",
    "        train_identifiers]\n",
    "    json_dict['test'] = [\"./imagesTs/%s.nii.gz\" % i for i in test_identifiers]\n",
    " \n",
    "    output_file += \"dataset.json\"\n",
    "    if not output_file.endswith(\"dataset.json\"):\n",
    "        print(\"WARNING: output file name is not dataset.json! This may be intentional or not. You decide. \"\n",
    "              \"Proceeding anyways...\")\n",
    "    save_json(json_dict, os.path.join(output_file))\n",
    " \n",
    " \n",
    "    \n",
    "output_file = r'/code/UniMiSS-code/UniMiSS/Downstream/DATASET/nnUNet_raw/nnUNet_raw_data/Task15_Neck/'\n",
    "imagesTr_dir = r'/code/UniMiSS-code/UniMiSS/Downstream/DATASET/nnUNet_raw/nnUNet_raw_data/Task15_Neck/imagesTr/'\n",
    "imagesTs_dir = r'/code/UniMiSS-code/UniMiSS/Downstream/DATASET/nnUNet_raw/nnUNet_raw_data/Task15_Neck/imagesTs/'\n",
    "# imagesTs_dir = None\n",
    "labelsTr = r'/code/UniMiSS-code/UniMiSS/Downstream/DATASET/nnUNet_raw/nnUNet_raw_data/Task15_Neck/labelsTr/'\n",
    "\n",
    "modalities = '\"0\": \"CT\"'\n",
    "labels = {\n",
    "    \"0\": \"background\",\n",
    "    \"1\": \"foreground\",\n",
    "}\n",
    "\n",
    "get_identifiers_from_splitted_files(output_file)\n",
    "generate_dataset_json(output_file,\n",
    "                        imagesTr_dir,\n",
    "                        imagesTs_dir,\n",
    "                        labelsTr,\n",
    "                        modalities,\n",
    "                        labels\n",
    "                        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## foreground background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, subfiles\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    " \n",
    "def get_identifiers_from_splitted_files(folder: str):\n",
    "    \n",
    "    uniques = np.unique([i[:-7] for i in subfiles(folder, suffix='.nii.gz', join=False)])\n",
    "    return uniques\n",
    " \n",
    "def generate_dataset_json(output_file: str, imagesTr_dir: str, imagesTs_dir: str, modalities: Tuple,\n",
    "                          labels: dict, dataset_name: str, license: str = \"AIML\", dataset_description: str = \"\",\n",
    "                          dataset_reference=\"oai-zib\", dataset_release='11/2021'):\n",
    "    \"\"\"\n",
    "    :param output_file: This needs to be the full path to the dataset.json you intend to write, so\n",
    "    output_file='DATASET_PATH/dataset.json' where the folder DATASET_PATH points to is the one with the\n",
    "    imagesTr and labelsTr subfolders\n",
    "    :param imagesTr_dir: path to the imagesTr folder of that dataset\n",
    "    :param imagesTs_dir: path to the imagesTs folder of that dataset. Can be None\n",
    "    :param modalities: tuple of strings with modality names. must be in the same order as the images (first entry\n",
    "    corresponds to _0000.nii.gz, etc). Example: ('T1', 'T2', 'FLAIR').\n",
    "    :param labels: dict with int->str (key->value) mapping the label IDs to label names. Note that 0 is always\n",
    "    supposed to be background! Example: {0: 'background', 1: 'edema', 2: 'enhancing tumor'}\n",
    "    :param dataset_name: The name of the dataset. Can be anything you want\n",
    "    :param license:\n",
    "    :param dataset_description:\n",
    "    :param dataset_reference: website of the dataset, if available\n",
    "    :param dataset_release:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_identifiers = get_identifiers_from_splitted_files(imagesTr_dir)\n",
    " \n",
    "    if imagesTs_dir is not None:\n",
    "        test_identifiers = get_identifiers_from_splitted_files(imagesTs_dir)\n",
    "    else:\n",
    "        test_identifiers = []\n",
    " \n",
    "    json_dict = {}\n",
    "    json_dict['name'] = \"bleedbrain\"\n",
    "    json_dict['description'] = \"bleedbrain\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = dataset_reference\n",
    "    json_dict['licence'] = license\n",
    "    json_dict['release'] = dataset_release\n",
    "    json_dict['modality'] = {\"0\": \"CT\"}\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"foreground\",\n",
    "    }\n",
    " \n",
    "    json_dict['numTraining'] = len(train_identifiers)\n",
    "    json_dict['numTest'] = len(test_identifiers)\n",
    "    json_dict['training'] = [\n",
    "        {'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i\n",
    "        in\n",
    "        train_identifiers]\n",
    "    json_dict['test'] = [\"./imagesTs/%s.nii.gz\" % i for i in test_identifiers]\n",
    " \n",
    "    output_file += \"dataset.json\"\n",
    "    if not output_file.endswith(\"dataset.json\"):\n",
    "        print(\"WARNING: output file name is not dataset.json! This may be intentional or not. You decide. \"\n",
    "              \"Proceeding anyways...\")\n",
    "    save_json(json_dict, os.path.join(output_file))\n",
    " \n",
    " \n",
    "    \n",
    "output_file = r'/code/nnUNetFrame/DATASET/nnUNet_raw/nnUNet_raw_data/Task96_traintest_foreback'\n",
    "imagesTr_dir = r'/code/nnUNetFrame/DATASET/nnUNet_raw/nnUNet_raw_data/Task96_traintest_foreback/imagesTr'\n",
    "imagesTs_dir = r'/code/nnUNetFrame/DATASET/nnUNet_raw/nnUNet_raw_data/Task96_traintest_foreback/imagesTs'\n",
    "# imagesTs_dir = None\n",
    "labelsTr = r'/code/nnUNetFrame/DATASET/nnUNet_raw/nnUNet_raw_data/Task96_traintest_foreback/labelsTr'\n",
    "\n",
    "modalities = '\"0\": \"CT\"'\n",
    "labels = {\n",
    "    \"0\": \"background\",\n",
    "    \"1\": \"epidural\",\n",
    "    \"2\": \"intraparenchymal\",\n",
    "    \"3\": \"intraventricular\",\n",
    "    \"4\": \"subarachnoid\",\n",
    "    \"5\": \"subdural\",\n",
    "}\n",
    "\n",
    "get_identifiers_from_splitted_files(output_file)\n",
    "generate_dataset_json(output_file,\n",
    "                        imagesTr_dir,\n",
    "                        imagesTs_dir,\n",
    "                        labelsTr,\n",
    "                        modalities,\n",
    "                        labels\n",
    "                        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
